{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(\n",
    "    \"../data/csv/playlists_dataset/spotify_dataset.csv\", on_bad_lines=\"skip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = base_df[[\"trackname\", \"playlistname\", \"artistname\", \"user_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the var types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trackname       string[python]\n",
      "playlistname    string[python]\n",
      "artistname      string[python]\n",
      "user_id         string[python]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "clean_df[\"trackname\"] = clean_df[\"trackname\"].astype(\"string\")\n",
    "clean_df[\"playlistname\"] = clean_df[\"playlistname\"].astype(\"string\")\n",
    "clean_df[\"artistname\"] = clean_df[\"artistname\"].astype(\"string\")\n",
    "clean_df[\"user_id\"] = clean_df[\"user_id\"].astype(\"string\")\n",
    "\n",
    "print(clean_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining trackname and artistname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the trackname and artistname into one string identify individual songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"track_and_artist\"] = clean_df[\"trackname\"] + \" \" + clean_df[\"artistname\"]\n",
    "clean_df[\"playlist_and_user_id\"] = clean_df[\"playlistname\"] + \" \" + clean_df[\"user_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering wrong playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's pretty sure that the extremly long playlists exist because of equal names of different playlists like \"love\" or \"rock\" ... \n",
    "Need to investigate if every user id is connected to one playlist or how it works out if multiple users work on one playlist... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_sizes = clean_df.groupby(\"playlist_and_user_id\").size()\n",
    "\n",
    "# Compute the lower and upper quantiles\n",
    "lower_n_percent_threshold = playlist_sizes.quantile(0.20)\n",
    "upper_n_percent_threshold = playlist_sizes.quantile(0.98)\n",
    "\n",
    "# Keep only those playlists within the specified size range\n",
    "valid_playlists = playlist_sizes[\n",
    "    (playlist_sizes >= lower_n_percent_threshold)\n",
    "    & (playlist_sizes <= upper_n_percent_threshold)\n",
    "].index\n",
    "\n",
    "# Filter the DataFrame to keep only valid playlists\n",
    "filtered_df = clean_df[clean_df[\"playlist_and_user_id\"].isin(valid_playlists)]\n",
    "\n",
    "clean_df = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest playlist length: 10\n"
     ]
    }
   ],
   "source": [
    "# Recompute the group sizes in the filtered DataFrame\n",
    "final_playlist_sizes = clean_df.groupby(\"playlist_and_user_id\").size()\n",
    "\n",
    "# Find the smallest playlist length\n",
    "smallest_playlist_length = final_playlist_sizes.min()\n",
    "\n",
    "print(\"Smallest playlist length:\", smallest_playlist_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"../data/csv/playlists_dataset/playlist_data_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/csv/playlists_dataset/playlist_data_v3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_playlist_np = clean_df.groupby(\"playlist_and_user_id\")[\n",
    "    \"track_and_artist\"\n",
    "].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_playlist = tokenized_playlist_np.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "temp_arr = tokenized_playlist_np\n",
    "\n",
    "extrapolated_data = tokenized_playlist\n",
    "\n",
    "# Shuffle each sub-array n times and collect results\n",
    "for subarray in temp_arr:\n",
    "    for _ in range(n):\n",
    "        extrapolated_data.append(np.random.permutation(subarray).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735012"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extrapolated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = extrapolated_data\n",
    "\n",
    "# split value\n",
    "split_fac = 0.9\n",
    "\n",
    "max_idx = len(tokenized_data) - 1\n",
    "anchor = int(max_idx * split_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = tokenized_playlist[:anchor]\n",
    "test_set = tokenized_playlist[anchor:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/tokenized_data/playlist_names/dataset_train_v3.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_set, f)\n",
    "\n",
    "\n",
    "with open(\"../data/tokenized_data/playlist_names/dataset_test_v3.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_set, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - V2 \n",
    "This is an other part of the notebook to work with the freshly pulled spotify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/csv/playlists_dataset/playlist_data_spotify_fresh.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Basic DataFrame Info ---\")\n",
    "df.info()\n",
    "print(\"\\\\n\")\n",
    "\n",
    "print(\"--- Descriptive Statistics for Numerical Columns ---\")\n",
    "# errors='coerce' will turn unparsable dates into NaT (Not a Time).\n",
    "print(\"--- Descriptive Statistics for Object/Categorical Columns ---\")\n",
    "print(df.describe(include=[\"object\"]))\n",
    "print(\"\\\\n\")\n",
    "\n",
    "# --- 4. Value Counts for Key Columns ---\n",
    "print(\"--- Value Counts for Key Columns ---\")\n",
    "print(\"Number of unique playlists:\")\n",
    "print(df[\"playlist_id\"].nunique())\n",
    "\n",
    "print(\"Number of unique tracks (by ID):\")\n",
    "print(df[\"track_id\"].nunique())\n",
    "print(\"\\\\n\")\n",
    "\n",
    "print(\"Number of unique track names:\")\n",
    "print(df[\"track_name\"].nunique())\n",
    "print(\"\\\\n\")\n",
    "\n",
    "# Artist Analysis - Handling comma-separated artists\n",
    "print(\"--- Artist Analysis ---\")\n",
    "# Ensure artist_name is treated as string and handle potential NaNs before splitting\n",
    "df[\"artist_name\"] = df[\"artist_name\"].astype(\n",
    "    str\n",
    ")  # Convert to string to use .str methods\n",
    "all_artists = df[\"artist_name\"].str.split(\",\\\\s*\").explode().str.strip()\n",
    "# Remove 'nan' strings if they resulted from original NaNs converted to string\n",
    "all_artists = all_artists[all_artists.str.lower() != \"nan\"]\n",
    "\n",
    "print(\"Number of unique individual artists:\")\n",
    "print(all_artists.nunique())\n",
    "print(\"\\\\nTop 10 most frequent individual artists:\")\n",
    "print(all_artists.value_counts().nlargest(10))\n",
    "print(\"\\\\n\")\n",
    "\n",
    "# --- Playlist Analysis: Tracks per Playlist ---\n",
    "print(\"--- Tracks per Playlist Analysis ---\")\n",
    "tracks_per_playlist = (\n",
    "    df.groupby(\"playlist_id\")[\"track_id\"].count().sort_values(ascending=False)\n",
    ")\n",
    "print(tracks_per_playlist)\n",
    "print(\"\\\\n\")\n",
    "\n",
    "# --- Most Frequent Track Names ---\n",
    "print(\"--- Most Frequent Track Names ---\")\n",
    "# Consider that track names might not be unique (e.g. remixes, covers, same name different artist)\n",
    "print(df[\"track_name\"].value_counts().nlargest(10))\n",
    "print(\"\\\\n\")\n",
    "\n",
    "# --- Missing Values ---\n",
    "print(\"--- Missing Values per Column ---\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\\\n\")\n",
    "\n",
    "print(\n",
    "    \"Basic analysis complete. You can expand on this with more specific questions about your data!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_external_urls</th>\n",
       "      <th>release_date</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5owFYKDZnehRxuuOLk36iS</td>\n",
       "      <td>1MDyUzZgyrdeQVmV1FU3WQ</td>\n",
       "      <td>Als du gingst - edit</td>\n",
       "      <td>https://open.spotify.com/track/1MDyUzZgyrdeQVm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contec, Lina Maly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5owFYKDZnehRxuuOLk36iS</td>\n",
       "      <td>3t854jxXLppSGbOEYGQ3mI</td>\n",
       "      <td>Shake That</td>\n",
       "      <td>https://open.spotify.com/track/3t854jxXLppSGbO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sonny Wern, Danimal, okafuwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5owFYKDZnehRxuuOLk36iS</td>\n",
       "      <td>5yujUAF2VoPWKfYMKoBqSK</td>\n",
       "      <td>Wie? - Techno</td>\n",
       "      <td>https://open.spotify.com/track/5yujUAF2VoPWKfY...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FUTURAMI, XEKNO!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5owFYKDZnehRxuuOLk36iS</td>\n",
       "      <td>4zRKaWqz94saRIpW5hPcHC</td>\n",
       "      <td>STARGAZING - TECHNO</td>\n",
       "      <td>https://open.spotify.com/track/4zRKaWqz94saRIp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XEKNO!, TEKTOSHI, VXLTAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5owFYKDZnehRxuuOLk36iS</td>\n",
       "      <td>0bb1R14dsWjFO01iJ6GqF3</td>\n",
       "      <td>SHE DOESN'T MIND - TECHNO</td>\n",
       "      <td>https://open.spotify.com/track/0bb1R14dsWjFO01...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PSYKADELIK, TEKTOSHI, Phantom X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              playlist_id                track_id                 track_name  \\\n",
       "0  5owFYKDZnehRxuuOLk36iS  1MDyUzZgyrdeQVmV1FU3WQ       Als du gingst - edit   \n",
       "1  5owFYKDZnehRxuuOLk36iS  3t854jxXLppSGbOEYGQ3mI                 Shake That   \n",
       "2  5owFYKDZnehRxuuOLk36iS  5yujUAF2VoPWKfYMKoBqSK              Wie? - Techno   \n",
       "3  5owFYKDZnehRxuuOLk36iS  4zRKaWqz94saRIpW5hPcHC        STARGAZING - TECHNO   \n",
       "4  5owFYKDZnehRxuuOLk36iS  0bb1R14dsWjFO01iJ6GqF3  SHE DOESN'T MIND - TECHNO   \n",
       "\n",
       "                                 track_external_urls  release_date  \\\n",
       "0  https://open.spotify.com/track/1MDyUzZgyrdeQVm...           NaN   \n",
       "1  https://open.spotify.com/track/3t854jxXLppSGbO...           NaN   \n",
       "2  https://open.spotify.com/track/5yujUAF2VoPWKfY...           NaN   \n",
       "3  https://open.spotify.com/track/4zRKaWqz94saRIp...           NaN   \n",
       "4  https://open.spotify.com/track/0bb1R14dsWjFO01...           NaN   \n",
       "\n",
       "                       artist_name  \n",
       "0                Contec, Lina Maly  \n",
       "1     Sonny Wern, Danimal, okafuwa  \n",
       "2                 FUTURAMI, XEKNO!  \n",
       "3        XEKNO!, TEKTOSHI, VXLTAGE  \n",
       "4  PSYKADELIK, TEKTOSHI, Phantom X  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5362389\n",
      "3492451\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df_cleaned = df.drop_duplicates(subset=[\"playlist_id\", \"track_id\"], keep=\"first\")\n",
    "print(len(df_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = df_cleaned.groupby(\"playlist_id\")[\"track_id\"].apply(list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46515"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(tokenized_data)\n",
    "\n",
    "split_90_percent = int(data_length * 0.90)\n",
    "split_95_percent = int(data_length * 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = tokenized_data[:split_90_percent]\n",
    "validation_set = tokenized_data[split_90_percent:split_95_percent]\n",
    "test_set = tokenized_data[split_95_percent:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"../data/tokenized_data/playlist_names/fresh_dataset_train_v1.pkl\", \"wb\"\n",
    ") as f:\n",
    "    pickle.dump(training_set, f)\n",
    "\n",
    "with open(\"../data/tokenized_data/playlist_names/fresh_dataset_val_v1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(validation_set, f)\n",
    "\n",
    "with open(\"../data/tokenized_data/playlist_names/fresh_dataset_test_v1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_set, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
